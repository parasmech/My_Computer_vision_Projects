{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5012d4-ad63-4b35-85cd-4a81460e8223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to detect keypoints and describe them as feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba880afe-265d-4c04-b107-04a702e757a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /home/parasubu/.local/lib/python3.10/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: opencv-contrib-python in /home/parasubu/.local/lib/python3.10/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/parasubu/.local/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1847e128-3c28-4715-8985-5f879c2042f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de09b923-2713-4455-8085-bf0e4abe3573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def keypoints_features(gray_image):\n",
    "    descriptor =cv2.xfeatures2d.SIFT_create()\n",
    "    (kpts, features) = descriptor.detectAndCompute(gray_image, None)\n",
    "    keyPts = []\n",
    "    keyPts = np.float32([kp.pt for kp in kpts])\n",
    "    return (keyPts, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457da5f5-679c-4c53-8f39-616e2b6b4362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_pts(keypts_1, keypts_2, feature_1, feature_2, ratio = 0.75, thresh = 4.0):\n",
    "    match_method = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "    nearest_neighbor = 2\n",
    "    raw_matches = match_method.knnMatch(feature_1, feature_2, nearest_neighbor)\n",
    "    matches = []\n",
    "    for match in raw_matches:\n",
    "        if len(match) ==2 and match[0].distance < match[1].distance * ratio :\n",
    "            matches.append((match[0].trainIdx , match[0].queryIdx))\n",
    "    #print(matches)\n",
    "            \n",
    "    if len(matches) > 4:\n",
    "        pts_image1 = []\n",
    "        pts_image2 = []\n",
    "        for _, index in matches:\n",
    "            pts = np.float32(keypts_1[index])\n",
    "            pts = keypts_1[index]\n",
    "            pts_image1.append(pts)\n",
    "        #print(\"pts_image1\", pts_image1)\n",
    "            \n",
    "        for index, _ in matches:\n",
    "            pts = np.float32(keypts_2[index])\n",
    "            pts = keypts_2[index]\n",
    "            pts_image2.append(pts)\n",
    "            \n",
    "        pts_image1 = np.array(pts_image1, dtype = np.float32)\n",
    "        pts_image2 = np.array(pts_image2, dtype = np.float32)  \n",
    "        \n",
    "        (Homography_matrix, status) = cv2.findHomography(pts_image1, pts_image2, cv2.RANSAC, thresh)\n",
    "        return (matches, Homography_matrix, status)\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a683ef5f-c553-4c5a-a405-33b90c6acaaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_matches(image1, image2, keyPts_1, keyPts_2, matches, status):\n",
    "    (h_1, w_1) = image1.shape[0], image1.shape[1]\n",
    "    (h_2, w_2) = image2.shape[0], image2.shape[1]\n",
    "    stacked_image = np.zeros((max(h_1, h_2), w_1+w_2 ,3), dtype = 'uint8')\n",
    "    stacked_image[:h_1 , 0:w_1] = image1\n",
    "    stacked_image[:h_2 , w_1:] = image2\n",
    "    \n",
    "    for ((trainIdx, queryIdx), stat) in zip(matches, status):\n",
    "        if stat ==1:\n",
    "            pt_1 = (int(keyPts_1[queryIdx][0]), int(keyPts_1[queryIdx][1]))\n",
    "            pt_2 = (int(keyPts_2[trainIdx][0])+ w_1, int(keyPts_2[trainIdx][1]))\n",
    "            cv2.line(stacked_image, pt_1, pt_2, (0,0,255), 1)\n",
    "    return stacked_image\n",
    "                                                                 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2e8259-b7ee-4d99-a720-6234a39fef36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.107] global shadow_sift.hpp:13 SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Stitched_image :  (400, 800, 3)\n",
      "Size of cropped_image :  (400, 700, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image1 = cv2.imread(\"image1.png\")\n",
    "image2 = cv2.imread(\"image2.png\")\n",
    "\n",
    "r_w = 400\n",
    "r_h = 400\n",
    "\n",
    "image1 = cv2.resize(image1, (r_w, r_h), interpolation = cv2.INTER_AREA)\n",
    "image2 = cv2.resize(image2, (r_w, r_h), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "gray_image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "gray_image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "(kpts_1, features_1) = keypoints_features(gray_image2)\n",
    "(kpts_2, features_2) = keypoints_features(gray_image1)\n",
    "\n",
    "M = match_pts (kpts_1, kpts_2, features_1, features_2)\n",
    "if M is None:\n",
    "    print(\"No match found\")\n",
    "    exit()\n",
    "    \n",
    "(matches, Homography_matrix, status) = M\n",
    "stitched_image = cv2.warpPerspective(image2, Homography_matrix, (image1.shape[1] + image2.shape[1], image2.shape[0]))\n",
    "cv2.imwrite(\"stitched_image_pre.png\", stitched_image)\n",
    "\n",
    "stitched_image[0: image1.shape[0], 0:image1.shape[1]] = image1\n",
    "cv2.imwrite(\"stitched_image.png\", stitched_image)\n",
    "\n",
    "keypts_matchimage = visualize_matches(image1, image2, kpts_1, kpts_2, matches, status)\n",
    "#cv2.imshow(\"keypoints match \", keypts_matchimage)\n",
    "#cv2.imshow(\"stitched_image\", stitched_image)\n",
    "#cv2.imshow(\"Input_images and stitched image\", np.hstack((image1, image2, stitched_image)))\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# Cropping black region\n",
    "stitched_image_cropped = stitched_image[0:400, 0:700]\n",
    "cv2.imwrite(\"image_stitched_cropped.png\", stitched_image_cropped)\n",
    "\n",
    "print(\"Size of Stitched_image : \", stitched_image.shape)\n",
    "print(\"Size of cropped_image : \", stitched_image_cropped.shape)\n",
    "\n",
    "                                     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
